{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor:\n",
    "    def Extract(self, name):\n",
    "        data=pd.read_csv(name, sep=\",\", header=None,names= [\"sepal length\", \"sepal width\" , \"petal length\", \"petal width\", \"class\"])\n",
    "        data=data.sample(frac=0.5) #frac = fraction of rows to return in the random sample\n",
    "        data=data.iloc[:, 1:4]\n",
    "        return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import itertools\n",
    "import random\n",
    "# import copy\n",
    "from scipy.sparse import coo_matrix, dok_matrix\n",
    "class Granulator:\n",
    "    Symbol_Threshold = 0;\n",
    "    Lambda = 0;\n",
    "    def Process(self,dataset, theta, Q, dissimilarityFunction): #SpareBSAS\n",
    "        \"\"\" Modified two-pass BSAS with approximate medoid tracking from the SPARE library\n",
    "\n",
    "        Input:\n",
    "        - dataset: list of items to be processed\n",
    "        - theta: real-valued dissimilarity threshold for pattern inclusion\n",
    "        - Q: maximum number of allowed clusters\n",
    "        - dissimilarityFunction: callable for the dissimilarity measure to be used\n",
    "        Output:\n",
    "        - clusters: list of clusters' pattern IDs\n",
    "        - representatives: list of clusters' medoids\n",
    "        - representatives_IDs: list of clusters' medoid IDs\n",
    "        - clusters_DissimMatrix: list of clusters' dissimilarity matrices. \"\"\"\n",
    "        # Set useful parameters\n",
    "        poolSize = 20\n",
    "\n",
    "        # Misc\n",
    "        isAssigned = [False] * len(dataset)\n",
    "\n",
    "        # First Round\n",
    "        clusters = [[0]]                    # first pattern\n",
    "        representatives = [dataset[0]]      # is\n",
    "        representatives_IDs = [0]           # first cluster\n",
    "        isAssigned[0] = True                #\n",
    "\n",
    "        for i in range(1, len(dataset)):\n",
    "            # grab current point\n",
    "            point = dataset[i]\n",
    "\n",
    "            # find distances w.r.t. all clusters\n",
    "            distances = [dissimilarityFunction(point, medoid) for medoid in representatives]\n",
    "            index_cluster = numpy.argmin(distances)\n",
    "            distance = distances[index_cluster]\n",
    "\n",
    "            if distance > theta and len(clusters) < Q:\n",
    "                representatives.append(point)\n",
    "                clusters.append([i])\n",
    "                representatives_IDs.append(i)\n",
    "                isAssigned[i] = True\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # Second Round\n",
    "        clusters_DissimMatrix = [numpy.zeros((1, 1))] * len(clusters)\n",
    "        for i in range(0, len(dataset)):\n",
    "            if isAssigned[i] is False:\n",
    "                # grab current point\n",
    "                point = dataset[i]\n",
    "                # find distances w.r.t. all clusters\n",
    "                distances = [dissimilarityFunction(point, medoid) for medoid in representatives]\n",
    "                index_cluster = numpy.argmin(distances)\n",
    "                distance = distances[index_cluster]\n",
    "                # update medoid\n",
    "                if len(clusters[index_cluster]) < poolSize:\n",
    "                    clusters[index_cluster].append(i)\n",
    "\n",
    "                    D = numpy.zeros((len(clusters[index_cluster]), len(clusters[index_cluster])))\n",
    "                    D[:-1, :-1] = clusters_DissimMatrix[index_cluster]\n",
    "\n",
    "                    v_left, v_right = [], []\n",
    "                    for j, k in itertools.product([D.shape[1] - 1], range(D.shape[0] - 1)):\n",
    "                        v_left.append(dissimilarityFunction(dataset[clusters[index_cluster][j]], dataset[clusters[index_cluster][k]]))\n",
    "                    for j, k in itertools.product(range(D.shape[1] - 1), [D.shape[0] - 1]):\n",
    "                        v_right.append(dissimilarityFunction(dataset[clusters[index_cluster][j]], dataset[clusters[index_cluster][k]]))\n",
    "                    v = 0.5 * (numpy.array(v_left) + numpy.array(v_right))\n",
    "                    D[0:-1, -1] = v\n",
    "                    D[-1, 0:-1] = v\n",
    "                    minSOD_ID = numpy.argmin(numpy.sum(D, axis=1))\n",
    "                else:\n",
    "                    id_pattern1, id_pattern2 = random.sample(range(0, poolSize), 2)\n",
    "                    id_medoid = clusters[index_cluster].index(representatives_IDs[index_cluster])\n",
    "                    # old_D = clusters_DissimMatrix[index_cluster]\n",
    "                    # d1 = old_D[id_medoid, id_pattern1]\n",
    "                    # d2 = old_D[id_medoid, id_pattern2]\n",
    "                    # if d1 >= d2:\n",
    "                    #     old_D = numpy.delete(old_D, (id_pattern1), axis=0)\n",
    "                    #     old_D = numpy.delete(old_D, (id_pattern1), axis=1)\n",
    "                    #     del clusters[index_cluster][id_pattern1]\n",
    "                    # else:\n",
    "                    #     old_D = numpy.delete(old_D, (id_pattern2), axis=0)\n",
    "                    #     old_D = numpy.delete(old_D, (id_pattern2), axis=1)\n",
    "                    #     del clusters[index_cluster][id_pattern2]\n",
    "                    # clusters[index_cluster].append(i)\n",
    "                    # D = numpy.zeros((len(clusters[index_cluster]), len(clusters[index_cluster])))\n",
    "                    # D[:-1, :-1] = old_D\n",
    "                    # v_left, v_right = [], []\n",
    "                    # for j, k in itertools.product([D.shape[1] - 1], range(D.shape[0] - 1)):\n",
    "                    #     v_left.append(dissimilarityFunction(dataset[clusters[index_cluster][j]], dataset[clusters[index_cluster][k]]))\n",
    "                    # for j, k in itertools.product(range(D.shape[1] - 1), [D.shape[0] - 1]):\n",
    "                    #     v_right.append(dissimilarityFunction(dataset[clusters[index_cluster][j]], dataset[clusters[index_cluster][k]]))\n",
    "                    # v = 0.5 * (numpy.array(v_left) + numpy.array(v_right))\n",
    "                    # D[0:-1, -1] = v\n",
    "                    # D[-1, 0:-1] = v\n",
    "                    D = clusters_DissimMatrix[index_cluster]\n",
    "                    d1 = D[id_medoid, id_pattern1]\n",
    "                    d2 = D[id_medoid, id_pattern2]\n",
    "                    if d1 >= d2:\n",
    "                        toBeChanged = id_pattern1\n",
    "                    else:\n",
    "                        toBeChanged = id_pattern2\n",
    "                    clusters[index_cluster][toBeChanged] = i\n",
    "                    v_left, v_right = numpy.zeros(len(clusters[index_cluster])), numpy.zeros(len(clusters[index_cluster]))\n",
    "                    for j in numpy.setdiff1d(range(len(clusters[index_cluster])), toBeChanged):\n",
    "                        v_right[j] = dissimilarityFunction(dataset[clusters[index_cluster][j]], dataset[clusters[index_cluster][toBeChanged]])\n",
    "                        v_left[j] = dissimilarityFunction(dataset[clusters[index_cluster][toBeChanged]], dataset[clusters[index_cluster][j]])\n",
    "                    v = 0.5 * (v_left + v_right)\n",
    "                    D[:, toBeChanged] = v\n",
    "                    D[toBeChanged, :] = v\n",
    "                    minSOD_ID = numpy.argmin(numpy.sum(D, axis=1))\n",
    "                clusters_DissimMatrix[index_cluster] = D\n",
    "                representatives[index_cluster] = dataset[clusters[index_cluster][minSOD_ID]]\n",
    "                representatives_IDs[index_cluster] = clusters[index_cluster][minSOD_ID]\n",
    "        \n",
    "        print(\"clusters:\")\n",
    "        print(clusters)\n",
    "        print(\"representatives:\")\n",
    "        print(representatives)\n",
    "        print(\"representatives_IDs\")\n",
    "        print(representatives_IDs)\n",
    "        print(\"clusters_DissimMatrix\")\n",
    "        print(clusters_DissimMatrix)\n",
    "        return clusters, representatives, representatives_IDs, clusters_DissimMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    Symbol_Threshold = 0;\n",
    "    Labda = 0;\n",
    "    ClusteringParams = 0;\n",
    "    MetricParams = 0;\n",
    "    def Extract(self, name):\n",
    "        e = Extractor(); #dichiaro oggetto di tipo Extractor\n",
    "        data_frame = e.Extract('iris_data.txt')\n",
    "        return data_frame\n",
    "    def Granulate(self, dataset, theta, Q, dissimilarityFunction):\n",
    "        g = Granulator(); #dichiaro oggetto di tipo Granulator\n",
    "        g.Process(dataset, theta, Q,dissimilarityFunction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    Weight_Params = 0;\n",
    "    def Diss(self,a, b):\n",
    "        dst = distance.euclidean(a, b)\n",
    "        return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Granule:\n",
    "    Compactness = 0;\n",
    "    Cardinality = 0;\n",
    "    Effective_Radius = 0;\n",
    "    Quality = 0;\n",
    "    Representative = 0;\n",
    "    Metric = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal width  petal length  petal width\n",
      "69           2.5           3.9          1.1\n",
      "58           2.9           4.6          1.3\n",
      "42           3.2           1.3          0.2\n",
      "25           3.0           1.6          0.2\n",
      "66           3.0           4.5          1.5\n",
      "..           ...           ...          ...\n",
      "115          3.2           5.3          2.3\n",
      "72           2.5           4.9          1.5\n",
      "49           3.3           1.4          0.2\n",
      "78           2.9           4.5          1.5\n",
      "99           2.8           4.1          1.3\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "x1 = Agent()\n",
    "df=x1.Extract('iris_data.txt')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters:\n",
      "[[37, 74, 70, 71, 73, 69, 68, 49, 40, 72, 34, 27, 45, 66, 67, 15, 63, 26, 53, 58]]\n",
      "representatives:\n",
      "[3.0]\n",
      "representatives_IDs\n",
      "[37]\n",
      "clusters_DissimMatrix\n",
      "[array([[0. , 0.2, 0.2, 0.5, 0.1, 0.1, 0.5, 0. , 0. , 0.3, 0.1, 0. , 0.4,\n",
      "        0.2, 0.4, 0. , 0.8, 0. , 0.2, 0. ],\n",
      "       [0.2, 0. , 0.4, 0.3, 0.1, 0.1, 0.7, 0.2, 0.2, 0.5, 0.1, 0.2, 0.6,\n",
      "        0. , 0.6, 0.2, 1. , 0.2, 0. , 0.2],\n",
      "       [0.2, 0.4, 0. , 0.7, 0.3, 0.3, 0.3, 0.2, 0.2, 0.1, 0.3, 0.2, 0.2,\n",
      "        0.4, 0.2, 0.2, 0.6, 0.2, 0.4, 0.2],\n",
      "       [0.5, 0.3, 0.7, 0. , 0.4, 0.4, 1. , 0.5, 0.5, 0.8, 0.4, 0.5, 0.9,\n",
      "        0.3, 0.9, 0.5, 1.3, 0.5, 0.3, 0.5],\n",
      "       [0.1, 0.1, 0.3, 0.4, 0. , 0. , 0.6, 0.1, 0.1, 0.4, 0. , 0.1, 0.5,\n",
      "        0.1, 0.5, 0.1, 0.9, 0.1, 0.1, 0.1],\n",
      "       [0.1, 0.1, 0.3, 0.4, 0. , 0. , 0.6, 0.1, 0.1, 0.4, 0. , 0.1, 0.5,\n",
      "        0.1, 0.5, 0.1, 0.9, 0.1, 0.1, 0.1],\n",
      "       [0.5, 0.7, 0.3, 1. , 0.6, 0.6, 0. , 0.5, 0.5, 0.2, 0.6, 0.5, 0.1,\n",
      "        0.7, 0.1, 0.5, 0.3, 0.5, 0.7, 0.5],\n",
      "       [0. , 0.2, 0.2, 0.5, 0.1, 0.1, 0.5, 0. , 0. , 0.3, 0.1, 0. , 0.4,\n",
      "        0.2, 0.4, 0. , 0.8, 0. , 0.2, 0. ],\n",
      "       [0. , 0.2, 0.2, 0.5, 0.1, 0.1, 0.5, 0. , 0. , 0.3, 0.1, 0. , 0.4,\n",
      "        0.2, 0.4, 0. , 0.8, 0. , 0.2, 0. ],\n",
      "       [0.3, 0.5, 0.1, 0.8, 0.4, 0.4, 0.2, 0.3, 0.3, 0. , 0.4, 0.3, 0.1,\n",
      "        0.5, 0.1, 0.3, 0.5, 0.3, 0.5, 0.3],\n",
      "       [0.1, 0.1, 0.3, 0.4, 0. , 0. , 0.6, 0.1, 0.1, 0.4, 0. , 0.1, 0.5,\n",
      "        0.1, 0.5, 0.1, 0.9, 0.1, 0.1, 0.1],\n",
      "       [0. , 0.2, 0.2, 0.5, 0.1, 0.1, 0.5, 0. , 0. , 0.3, 0.1, 0. , 0.4,\n",
      "        0.2, 0.4, 0. , 0.8, 0. , 0.2, 0. ],\n",
      "       [0.4, 0.6, 0.2, 0.9, 0.5, 0.5, 0.1, 0.4, 0.4, 0.1, 0.5, 0.4, 0. ,\n",
      "        0.6, 0. , 0.4, 0.4, 0.4, 0.6, 0.4],\n",
      "       [0.2, 0. , 0.4, 0.3, 0.1, 0.1, 0.7, 0.2, 0.2, 0.5, 0.1, 0.2, 0.6,\n",
      "        0. , 0.6, 0.2, 1. , 0.2, 0. , 0.2],\n",
      "       [0.4, 0.6, 0.2, 0.9, 0.5, 0.5, 0.1, 0.4, 0.4, 0.1, 0.5, 0.4, 0. ,\n",
      "        0.6, 0. , 0.4, 0.4, 0.4, 0.6, 0.4],\n",
      "       [0. , 0.2, 0.2, 0.5, 0.1, 0.1, 0.5, 0. , 0. , 0.3, 0.1, 0. , 0.4,\n",
      "        0.2, 0.4, 0. , 0.8, 0. , 0.2, 0. ],\n",
      "       [0.8, 1. , 0.6, 1.3, 0.9, 0.9, 0.3, 0.8, 0.8, 0.5, 0.9, 0.8, 0.4,\n",
      "        1. , 0.4, 0.8, 0. , 0.8, 1. , 0.8],\n",
      "       [0. , 0.2, 0.2, 0.5, 0.1, 0.1, 0.5, 0. , 0. , 0.3, 0.1, 0. , 0.4,\n",
      "        0.2, 0.4, 0. , 0.8, 0. , 0.2, 0. ],\n",
      "       [0.2, 0. , 0.4, 0.3, 0.1, 0.1, 0.7, 0.2, 0.2, 0.5, 0.1, 0.2, 0.6,\n",
      "        0. , 0.6, 0.2, 1. , 0.2, 0. , 0.2],\n",
      "       [0. , 0.2, 0.2, 0.5, 0.1, 0.1, 0.5, 0. , 0. , 0.3, 0.1, 0. , 0.4,\n",
      "        0.2, 0.4, 0. , 0.8, 0. , 0.2, 0. ]])]\n"
     ]
    }
   ],
   "source": [
    "m1 = Metric()\n",
    "sepal_width_list=df[\"sepal width\"].tolist()\n",
    "x1.Granulate(sepal_width_list,2.1, 5,m1.Diss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
